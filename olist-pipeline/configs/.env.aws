# ========= RDS (Postgres) =========
POSTGRES_HOST=db-olist-dyk98.cpk2iyi6ejqs.ap-northeast-2.rds.amazonaws.com   # RDS 엔드포인트
POSTGRES_DB=olist                                              # 운영 DB 이름
POSTGRES_USER=olist                                            # 운영용 계정(마스터 X)
POSTGRES_PASSWORD=Kdea504605!                                  # 운영용 계정 비번

# Airflow DAG들이 사용할 연결 (conn_id = postgres_default)
AIRFLOW_CONN_POSTGRES_DEFAULT=postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:5432/${POSTGRES_DB}

# ========= S3 (RAW 데이터) =========
AWS_DEFAULT_REGION=ap-northeast-2
S3_BUCKET=olist-raw-dyk-e-commerce-olist
S3_PREFIX=                                                   # 예: olist/  (없으면 빈값)

# 중요: EC2 인스턴스 프로파일(IAM 역할)로 S3 접근하므로
# AWS_ACCESS_KEY_ID / AWS_SECRET_ACCESS_KEY / S3_ENDPOINT 는 설정하지 않습니다.
# (버킷이 SSE-KMS면 해당 KMS 키에 대해 역할에 kms:Decrypt 권한이 있어야 함)

# ========= Airflow 일반 =========
AIRFLOW__CORE__LOAD_EXAMPLES=False
SQL_DIR=/opt/airflow/sql

# (선택) Airflow 메타DB를 RDS에 따로 두고 싶다면 아래 주석 해제 후 값 채우기
# AIRFLOW_META_HOST=<RDS_ENDPOINT>
# AIRFLOW_META_DB=airflow
# AIRFLOW_META_USER=<계정>
# AIRFLOW_META_PASSWORD=<비번>
# AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://${AIRFLOW_META_USER}:${AIRFLOW_META_PASSWORD}@${AIRFLOW_META_HOST}:5432/${AIRFLOW_META_DB}

# ========== Slack =========
AIRFLOW_CONN_SLACK_WEBHOOK= https://hooks.slack.com/services/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 
SLACK_WEBHOOK_CONN_ID= incoming-webhook-olist
